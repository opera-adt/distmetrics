transformer_latest_config = {
    'patch_size': 8,
    'num_patches': 4,
    'data_dim': 128,
    'd_model': 256,
    'nhead': 4,
    'num_encoder_layers': 4,
    'dim_feedforward': 768,
    'max_seq_len': 10,
    'dropout': 0.2,
    'activation': 'relu',
}
